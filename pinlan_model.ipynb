{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pinlan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n",
      "1.16.2\n",
      "0.23.0\n",
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "print(lgb.__version__)\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    " \n",
    "def load_variavle(filename):\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r\n",
    "\n",
    "def get_path(path):\n",
    "    file_name = []\n",
    "    for i in os.listdir(path):\n",
    "        c = i.split('_')[0]\n",
    "        file_name.append(c)\n",
    "    file_name = list(set(file_name))\n",
    "    return file_name\n",
    "\n",
    "def lgb_recall_score(y_true, y_hat,t):\n",
    "    y_hat[y_hat>=t] = 1\n",
    "    y_hat[y_hat<t] = 0\n",
    "    return recall_score(y_true, y_hat, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_po_path = '../data/Motor_tain/Positive/'\n",
    "train_ne_path = '../data/Motor_tain/Negative/'\n",
    "train_po_file = get_path(train_po_path)\n",
    "train_ne_file = get_path(train_ne_path)\n",
    "test_path = '../data/Motor_testP/'\n",
    "test_file_name = get_path(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2056/2056 [04:19<00:00,  8.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/testf.pkl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(file_name,file_path):\n",
    "    fe = defaultdict(list)\n",
    "    for i in tqdm(file_name):\n",
    "        data_b = pd.read_csv(file_path + i + '_B.csv')\n",
    "        data_f = pd.read_csv(file_path + i +  '_F.csv')\n",
    "        data_b['p'] = np.sqrt(data_b.ai1**2+data_b.ai2**2)\n",
    "        data_f['p'] = np.sqrt(data_f.ai1**2+data_f.ai2**2)\n",
    "        fe['idx'].append(i)\n",
    "\n",
    "        fe['ai1_max_p'].append(data_b.p.max())\n",
    "        fe['ai1_min_p'].append(data_b.p.min())\n",
    "        fe['ai1_mean_p'].append(data_b.p.mean())\n",
    "        fe['ai1_abs_mean_p'].append(data_b.p.abs().mean())\n",
    "        fe['ai1_std_p'].append(data_b.p.std())\n",
    "        fe['ai1_abs_skew_p'].append(data_b.p.abs().skew())\n",
    "        fe['ai1_kurt_p'].append(data_b.p.kurt())\n",
    "        fe['ai1_rms_p'].append(np.sqrt(np.mean(data_b.p**2)))\n",
    "        \n",
    "        fe['circle_ratio_b'].append(data_b[data_b['p']<0.04].shape[0])\n",
    "        fe['ai1_0_b'].append(data_b[data_b['ai1']>0].shape[0])\n",
    "        fe['ai1_max_b'].append(data_b.ai1.max())\n",
    "        fe['ai1_min_b'].append(data_b.ai1.min())\n",
    "        fe['ai1_mean_b'].append(data_b.ai1.mean())\n",
    "        fe['ai1_abs_mean_b'].append(data_b.ai1.abs().mean())\n",
    "        fe['ai1_std_b'].append(data_b.ai1.std())\n",
    "        fe['ai1_abs_skew_b'].append(data_b.ai1.abs().skew())\n",
    "        fe['ai1_kurt_b'].append(data_b.ai1.kurt())\n",
    "        fe['ai1_rms_b'].append(np.sqrt(np.mean(data_b.ai1**2)))\n",
    "        \n",
    "        fe['ai2_max_b'].append(data_b.ai2.max())\n",
    "        fe['ai2_min_b'].append(data_b.ai2.min())\n",
    "        fe['ai2_mean_b'].append(data_b.ai2.mean())\n",
    "        fe['ai2_abs_mean_b'].append(data_b.ai2.abs().mean())\n",
    "        fe['ai2_std_b'].append(data_b.ai2.std())\n",
    "        fe['ai2_abs_skew_b'].append(data_b.ai2.abs().skew())\n",
    "        fe['ai2_kurt_b'].append(data_b.ai2.kurt())\n",
    "        fe['ai2_rms_b'].append(np.sqrt(np.mean(data_b.ai2**2)))\n",
    "        \n",
    "        fe['circle_ratio_f'].append(data_f[data_f['p']<0.04].shape[0])\n",
    "        fe['ai1_0_f'].append(data_f[data_f['ai1']>0].shape[0])\n",
    "        fe['ai1_max_f'].append(data_f.ai1.max())\n",
    "        fe['ai1_min_f'].append(data_f.ai1.min())\n",
    "        fe['ai1_mean_f'].append(data_f.ai1.mean())\n",
    "        fe['ai1_abs_mean_f'].append(data_f.ai1.abs().mean())\n",
    "        fe['ai1_std_f'].append(data_f.ai1.std())\n",
    "        fe['ai1_abs_skew_f'].append(data_f.ai1.abs().skew())\n",
    "        fe['ai1_kurt_f'].append(data_f.ai1.kurt())\n",
    "        fe['ai1_rms_f'].append(np.sqrt(np.mean(data_f.ai1**2)))\n",
    "        \n",
    "        fe['ai2_max_f'].append(data_f.ai2.max())\n",
    "        fe['ai2_min_f'].append(data_f.ai2.min())\n",
    "        fe['ai2_mean_f'].append(data_f.ai2.mean())\n",
    "        fe['ai2_abs_mean_f'].append(data_f.ai2.abs().mean())\n",
    "        fe['ai2_std_f'].append(data_f.ai2.std())\n",
    "        fe['ai2_abs_skew_f'].append(data_f.ai2.abs().skew())\n",
    "        fe['ai2_kurt_f'].append(data_f.ai2.kurt())\n",
    "        fe['ai2_rms_f'].append(np.sqrt(np.mean(data_f.ai2**2)))\n",
    "    return pd.DataFrame(fe)\n",
    "train = get_data(train_ne_file,train_ne_path)\n",
    "train['result'] = 0\n",
    "train_po = get_data(train_po_file,train_po_path)\n",
    "train_po['result'] = 1\n",
    "train = train.append(train_po).reset_index(drop=True)\n",
    "save_variable(train,'../data/train.pkl')\n",
    "test = get_data(test_file_name,test_path)\n",
    "save_variable(test,'../data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530, 46) (2056, 45)\n"
     ]
    }
   ],
   "source": [
    "train = load_variavle('../data/train.pkl')\n",
    "test = load_variavle('../data/test.pkl')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [i for i in train.columns if i not in ['idx', 'result']]\n",
    "X_train = train[col]\n",
    "y_train = train['result'].astype(int)\n",
    "X_test = test[col]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train),columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test),columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "seed = 2018\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "lgb_params = {\n",
    "                        'boosting_type': 'gbdt',\n",
    "                        'objective': 'binary',\n",
    "                        'metric': 'auc',\n",
    "                        'is_unbalance': True,\n",
    "                        'max_depth':6,\n",
    "                        'bagging_freq': 2,\n",
    "                        'bagging_seed':11,\n",
    "                        'lambda_l2': 0.2,\n",
    "                        'subsample': 0.8,\n",
    "                        'colsample_bytree': 0.6,\n",
    "                        'learning_rate': 0.1,\n",
    "                        'seed': 2017,\n",
    "                        'nthread': 6,\n",
    "                        'verbose':-1,\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.999583\tvalid_1's auc: 0.993333\n",
      "best iteration =  22\n",
      "fold 1\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.999115\tvalid_1's auc: 1\n",
      "best iteration =  7\n",
      "fold 2\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.996615\tvalid_1's auc: 1\n",
      "best iteration =  2\n",
      "fold 3\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's auc: 0.99875\tvalid_1's auc: 0.9925\n",
      "best iteration =  8\n",
      "fold 4\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.991667\tvalid_1's auc: 0.995\n",
      "best iteration =  2\n",
      "recall_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "score = []\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    print(\"fold {}\".format(i))\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_tr,y_tr)\n",
    "    lgb_val = lgb.Dataset(X_val,y_val)\n",
    "    num_round = 100\n",
    "    clf = lgb.train(lgb_params, lgb_train, num_round, valid_sets = [lgb_train, lgb_val],\n",
    "                    verbose_eval=-1, early_stopping_rounds = 10\n",
    "                   )\n",
    "    oof[val_index] = clf.predict(X_val, num_iteration=clf.best_iteration)\n",
    "    r_score = lgb_recall_score(y_val.values, clf.predict(X_val, num_iteration=clf.best_iteration),0.3)\n",
    "    score.append(r_score)\n",
    "    print('best iteration = ',clf.best_iteration)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = clf.feature_name()\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = i + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / skf.n_splits\n",
    "print('recall_score : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264086    888\n",
      "0.263792    230\n",
      "0.263546    221\n",
      "0.263411    215\n",
      "0.262889    200\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"lgb3500:0.63,\"\"\"\n",
    "sub = test[['idx']].copy()\n",
    "sub['result'] = predictions\n",
    "print(sub['result'].value_counts().head())\n",
    "sub = sub.sort_values('result').reset_index(drop=True)\n",
    "sub.loc[:3500,'result'] = 0\n",
    "sub.loc[3500:,'result'] = 1\n",
    "sub['result'] = sub['result'].astype(int)\n",
    "# sub.to_csv('../sub/lgb3500_fetrainpkl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_df.groupby('Feature')['importance'].mean().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['ai1_kurt_f', 'ai1_max_f', 'ai1_kurt_b', 'ai2_mean_f',\n",
    " 'ai2_abs_skew_b',  'ai2_kurt_b', 'ai1_mean_b', 'ai1_0_f',\n",
    " 'ai1_min_f', 'ai2_min_b', 'ai1_abs_skew_b', 'ai2_abs_mean_b', \n",
    " 'ai1_kurt_p', 'ai1_mean_f', 'ai1_mean_p', 'ai2_min_f']\n",
    "X_train = train[col]\n",
    "y_train = train['result'].astype(int)\n",
    "X_test = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "seed = 10086\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))\n",
    "score = []\n",
    "prec_score = []\n",
    "min_p = []\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    clf = AdaBoostClassifier(n_estimators=150, learning_rate=0.24)\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    oof[val_index] = clf.predict_proba(X_val)[:, 1]\n",
    "    r_score = lgb_recall_score(y_val.values, clf.predict_proba(X_val)[:, 1],0.0045)\n",
    "    score.append(r_score)\n",
    "    predictions += clf.predict_proba(X_test)[:, 1]\n",
    "print('recall_score : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001129    15\n",
      "0.000773    11\n",
      "0.009707     9\n",
      "0.007329     9\n",
      "0.006105     8\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sub = test[['idx']].copy()\n",
    "sub['result'] = predictions/5\n",
    "print(sub['result'].value_counts().head())\n",
    "sub = sub.sort_values('result').reset_index(drop=True)\n",
    "# sub.loc[:4200,'result'] = 0\n",
    "# sub.loc[4200:,'result'] = 1\n",
    "# sub['result'] = sub['result'].astype(int)\n",
    "# sub.to_csv('../sub/ada4200_fetrainpkl.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['ai1_kurt_f', 'ai1_max_f', 'ai1_kurt_b', 'ai2_mean_f',\n",
    " 'ai2_abs_skew_b',  'ai2_kurt_b', 'ai1_mean_b', 'ai1_0_f',\n",
    " 'ai1_min_f', 'ai2_min_b', 'ai1_abs_skew_b', 'ai2_abs_mean_b', \n",
    " 'ai1_kurt_p', 'ai1_mean_f', 'ai1_mean_p', 'ai2_min_f']\n",
    "X_train = train[col]\n",
    "y_train = train['result']\n",
    "X_test = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "seed = 195\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "recall_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))\n",
    "score = []\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    print(\"fold {}\".format(i))\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \"\"\"4,126\"\"\"\n",
    "    clf = RandomForestClassifier(max_depth=4,n_estimators=70,random_state=3)\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    oof[val_index] = clf.predict_proba(X_val)[:, 1]\n",
    "    r_score = lgb_recall_score(y_val.values, clf.predict_proba(X_val)[:, 1],0.0045)\n",
    "    score.append(r_score)\n",
    "    predictions += clf.predict_proba(X_test)[:, 1]\n",
    "print('recall_score : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000156    289\n",
      "0.000085    257\n",
      "0.000545    171\n",
      "0.000180    166\n",
      "0.000110    157\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sub = test[['idx']].copy()\n",
    "sub['result'] = predictions/5\n",
    "print(sub['result'].value_counts().head())\n",
    "sub = sub.sort_values('result').reset_index(drop=True)\n",
    "sub.loc[:2800,'result'] = 0\n",
    "sub.loc[2800:,'result'] = 1\n",
    "sub['result'] = sub['result'].astype(int)\n",
    "sub.to_csv('../sub/rf2800_fe_mybaseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "recall_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "col = ['ai1_kurt_f', 'ai1_max_f', 'ai1_kurt_b', 'ai2_mean_f',\n",
    " 'ai2_abs_skew_b',  'ai2_kurt_b', 'ai1_mean_b', 'ai1_0_f',\n",
    " 'ai1_min_f', 'ai2_min_b', 'ai1_abs_skew_b', 'ai2_abs_mean_b', \n",
    " 'ai1_kurt_p', 'ai1_mean_f', 'ai1_mean_p', 'ai2_min_f']\n",
    "X_train = train[col]\n",
    "y_train = train['result']\n",
    "X_test = test[col]\n",
    "\n",
    "K = 5\n",
    "seed = 985\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "\n",
    "\"\"\"归一化\"\"\"\n",
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))\n",
    "score = []\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    print(\"fold {}\".format(i))\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    clf = GradientBoostingClassifier(n_estimators=65, subsample = 0.86, learning_rate=0.105,\n",
    "                                     max_features='log2', random_state=6)\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    oof[val_index] = clf.predict_proba(X_val)[:, 1]\n",
    "    r_score = lgb_recall_score(y_val.values, clf.predict_proba(X_val)[:, 1],0.0045)\n",
    "    score.append(r_score)\n",
    "    predictions += clf.predict_proba(X_test)[:, 1]\n",
    "print('recall_score : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004793    160\n",
      "0.004755    128\n",
      "0.004739    109\n",
      "0.004701     97\n",
      "0.004790     78\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sub = test[['idx']].copy()\n",
    "sub['result'] = predictions/5\n",
    "print(sub['result'].value_counts().head())\n",
    "sub = sub.sort_values('result').reset_index(drop=True)\n",
    "sub.loc[:4000,'result'] = 0\n",
    "sub.loc[4000:,'result'] = 1\n",
    "sub['result'] = sub['result'].astype(int)\n",
    "sub.to_csv('../sub/gbdt4000_fe_my_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "recall_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "col = ['ai1_kurt_f', 'ai1_max_f', 'ai1_kurt_b', 'ai2_mean_f',\n",
    " 'ai2_abs_skew_b',  'ai2_kurt_b', 'ai1_mean_b', 'ai1_0_f',\n",
    " 'ai1_min_f', 'ai2_min_b', 'ai1_abs_skew_b', 'ai2_abs_mean_b', \n",
    " 'ai1_kurt_p', 'ai1_mean_f', 'ai1_mean_p', 'ai2_min_f']\n",
    "X_train = train[col]\n",
    "y_train = train['result']\n",
    "X_test = test[col]\n",
    "\n",
    "K = 5\n",
    "seed = 500\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "\n",
    "\"\"\"归一化\"\"\"\n",
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))\n",
    "score = []\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    print(\"fold {}\".format(i))\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    clf = ExtraTreesClassifier(n_estimators=66,max_depth=1,random_state=101)\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    oof[val_index] = clf.predict_proba(X_val)[:, 1]\n",
    "    r_score = lgb_recall_score(y_val.values, clf.predict_proba(X_val)[:, 1],0.0045)\n",
    "    score.append(r_score)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = col\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = i + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    predictions += clf.predict_proba(X_test)[:, 1]\n",
    "print('recall_score : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050492    24\n",
      "0.043109    22\n",
      "0.058298    20\n",
      "0.058481    19\n",
      "0.041893    15\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sub = test[['idx']].copy()\n",
    "sub['result'] = predictions/5\n",
    "print(sub['result'].value_counts().head())\n",
    "sub = sub.sort_values('result').reset_index(drop=True)\n",
    "sub.loc[:1200,'result'] = 0\n",
    "sub.loc[1200:,'result'] = 1\n",
    "sub['result'] = sub['result'].astype(int)\n",
    "sub.to_csv('../sub/ext1200_fe_my_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
